{"name":"Drudgery","body":"Drudgery is a simple ETL library that supports the following sources/destinations:\r\n\r\n * CSV and other delimited file formats (e.g. pipe, tab, etc)\r\n * SQLite3\r\n * ActiveRecord (bulk insert support using activerecord-import)\r\n\r\nSupported Rubies:\r\n\r\n * Ruby 1.9.2, 1.9.3\r\n\r\nInstall\r\n-------\r\n\r\nInstall the gem directly:\r\n\r\n```bash\r\ngem install drudgery\r\n```\r\n\r\nOr, add it to your Gemfile:\r\n\r\n```ruby\r\ngem 'drudgery'\r\n```\r\n\r\nAnd, if using the `:sqlite3` extractor or loader:\r\n\r\n```ruby\r\ngem 'sqlite3', '~> 1.3'\r\n```\r\n\r\nAnd, if using the `:active_record` extractor or loader:\r\n\r\n```ruby\r\ngem 'activerecord', '~> 3.0'\r\n```\r\n\r\nAnd, if using the `:active_record_import` loader:\r\n\r\n```ruby\r\ngem 'activerecord-import', '>= 0.2.9'\r\n```\r\n\r\nUsage\r\n-----\r\n\r\nExtracting from CSV and loading into ActiveRecord:\r\n\r\n```ruby\r\nm = Drudgery::Manager.new\r\n\r\nm.prepare do |job|\r\n  job.extract :csv, 'src/addresses.csv'\r\n\r\n  job.transform do |data, cache|\r\n    first_name, last_name = data.delete(:name).split(' ')\r\n\r\n    data[:first_name] = first_name\r\n    data[:last_name]  = last_name\r\n    data[:state]      = data.delete(:state_abbr)\r\n\r\n    data\r\n  end\r\n\r\n  job.load :active_record, Address\r\nend\r\n\r\nm.run\r\n```\r\n\r\nExtracting from SQLite3 and bulk loading into ActiveRecord:\r\n\r\n```ruby\r\ndb = SQLite3::Database.new('db.sqlite3')\r\n\r\nm = Drudgery::Manager.new\r\n\r\nm.prepare do |job|\r\n  job.batch_size 5000\r\n\r\n  job.extract :sqlite3, db, 'addresses' do |extractor|\r\n    extractor.select(\r\n      'name',\r\n      'street_address',\r\n      'city',\r\n      'state_abbr AS state',\r\n      'zip'\r\n    )\r\n    extractor.where(\"state LIKE 'A%'\")\r\n    extractor.order('name')\r\n  end\r\n\r\n  job.transform do |data, cache|\r\n    first_name, last_name = data.delete(:name).split(' ')\r\n\r\n    data[:first_name] = first_name\r\n    data[:last_name]  = last_name\r\n\r\n    data\r\n  end\r\n\r\n  job.load :active_record_import, Address\r\nend\r\n\r\nm.run\r\n```\r\n\r\nLogging\r\n-------\r\n\r\nProvide Drudgery with a logger and info will be logged about each job.\r\n\r\nWhen log level is `INFO` expect to see basic output for each job (e.g.\r\nwhen it starts and completes).\r\n\r\n```ruby\r\nlogger = Logger.new('log/etl.log')\r\nlogger.level = Logger::INFO # Logger defaults to log level DEBUG\r\n\r\nDrudgery.logger = logger\r\n```\r\n\r\nWhen log level is `DEBUG` expect to see output for each record\r\nextracted, transformed and loaded (VERY NOISY).\r\n\r\nProgress\r\n--------\r\n\r\nDrudgery also provides progress output to STDERR courtesty of the\r\n`progressbar` gem.  Progress output is on by default, but can be\r\ndisabled with the following:\r\n\r\n```ruby\r\nDrudgery.show_progress = false\r\n```\r\n\r\nExtractors\r\n----------\r\n\r\nThe following extractors are provided: `:csv`, `:sqlite3`, `:active_record`\r\n\r\nYou can use your own extractors if you would like.  They need to\r\nimplement the following methods:\r\n\r\n * `#name` - returns extractor's name\r\n * `#record_count` - returns count of records in source\r\n * `#extract` - must yield each record and record index\r\n\r\n```ruby\r\nclass ArrayExtractor\r\n  attr_reader :name\r\n\r\n  def initialize(source)\r\n    @source = source\r\n    @name = 'array'\r\n  end\r\n\r\n  def extract\r\n    index = 0\r\n    @source.each do |record|\r\n      yield [record, index]\r\n      index += 1\r\n    end\r\n  end\r\n\r\n  def record_count\r\n    @source.size\r\n  end\r\nend\r\n\r\nsource = []\r\n\r\nm = Drudgery::Manager.new\r\n\r\nm.prepare do |job|\r\n  m.extract ArrayExtractor.new(source)\r\n  m.load :csv, 'destination.csv'\r\nend\r\n```\r\n\r\nOr, if you define your custom extractor under the Drudgery::Extractors\r\nnamespace:\r\n\r\n```ruby\r\nmodule Drudgery\r\n  module Extractors\r\n    class ArrayExtractor\r\n      attr_reader :name\r\n\r\n      def initialize(source)\r\n        @source = source\r\n        @name = 'array'\r\n      end\r\n\r\n      def extract\r\n        index = 0\r\n        @source.each do |record|\r\n          yield [record, index]\r\n          index += 1\r\n        end\r\n      end\r\n\r\n      def record_count\r\n        @source.size\r\n      end\r\n    end\r\n  end\r\nend\r\n\r\nsource = []\r\n\r\nm = Drudgery::Manager.new\r\n\r\nm.prepare do |job|\r\n  m.extract :array, source\r\n  m.load :csv, 'destination.csv'\r\nend\r\n```\r\n\r\nTransformers\r\n------------\r\n\r\nDrudgery comes with a basic Transformer class.  It symbolizes the keys of\r\neach record and allows you to register a processor to process data.  The\r\nprocessor should implement a `#call` method and return a `Hash` or `nil`.\r\n\r\n```ruby\r\ncustom_processor = Proc.new do |data, cache|\r\n  data[:initials] = data[:name].split(' ').map(&:capitalize).join()\r\n  data\r\nend\r\n\r\ntransformer = Drudgery::Transformer.new\r\ntransformer.register(custom_processor)\r\n\r\ntransformer.transform({ :name => 'John Doe' }) # == { :name => 'John Doe', :initials => 'JD' }\r\n```\r\n\r\nYou could also implement your own transformer if you need more custom\r\nprocessing power.  If you inherit from `Drudgery::Transfomer`, you need\r\nonly implement the `#transform` method that accepts a hash argument as an\r\nargument and returns a `Hash` or `nil`.\r\n\r\n```ruby\r\nclass CustomTransformer < Drudgery::Transformer\r\n  def transform(data)\r\n    # do custom processing here\r\n  end\r\nend\r\n\r\nm = Drudgery::Manager.new\r\n\r\nm.prepare do |job|\r\n  m.extract :csv, 'source.csv'\r\n  m.transform CustomTransformer.new\r\n  m.load :csv, 'destination.csv'\r\nend\r\n```\r\n\r\nLoaders\r\n-------\r\n\r\nThe following loaders are provided:\r\n\r\n * `:csv`\r\n * `:sqlite3`\r\n * `:active_record`\r\n * `:active_record_import`\r\n\r\nYou can use your own loaders if you would like.  They need to implement\r\nthe following methods:\r\n\r\n* `#name` - returns the loader's name\r\n* `#load` - accepts an array of records and then write them to the\r\n  destination\r\n\r\n```ruby\r\nclass ArrayLoader\r\n  attr_reader :name\r\n\r\n  def initialize(destination)\r\n    @destination = destination\r\n    @name = 'array'\r\n  end\r\n\r\n  def load(records)\r\n    @destination.push(*records)\r\n  end\r\nend\r\n\r\ndestination = []\r\n\r\nm = Drudgery::Manager.new\r\n\r\nm.prepare do |job|\r\n  m.extract :csv, 'source.csv'\r\n  m.load ArrayLoader.new(destination)\r\nend\r\n```\r\n\r\nOr, if you define your custom loader under the Drudgery::Loaders\r\nnamespace:\r\n\r\n```ruby\r\nmodule Drudgery\r\n  module Loaders\r\n    class ArrayLoader\r\n      attr_reader :name\r\n\r\n      def initialize(destination)\r\n        @destination = destination\r\n        @name = 'array'\r\n      end\r\n\r\n      def load(records)\r\n        @destination.push(*records)\r\n      end\r\n    end\r\n  end\r\nend\r\n\r\ndestination = []\r\n\r\nm = Drudgery::Manager.new\r\n\r\nm.prepare do |job|\r\n  m.extract :csv, 'source.csv'\r\n  m.load :array, destination\r\nend\r\n```","tagline":"A simple ETL library","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}